# core/evaluators.py

import logging
import time
import tracemalloc

logger = logging.getLogger(__name__)


def evaluate_rule(rule_func, sequence):
    """
    Evaluates a generated rule function against a sequence.

    :param rule_func: The function generated by sequence_rule_generator
    :param sequence: The input sequence of objects
    :return: Boolean indicating rule satisfaction and optional failure details
    """
    if not callable(rule_func):
        logger.error("Provided rule function is not callable!")
        return False, "Invalid function"

    if not sequence:
        logger.warning("Attempted to evaluate an empty sequence.")
        return False, "Empty sequence"

    logger.debug(f"Evaluating sequence: {[obj.name for obj in sequence]}")

    try:
        start_time = time.perf_counter()
        result = rule_func(sequence)
        elapsed_time = time.perf_counter() - start_time

        logger.info(
            f"Rule evaluation result: {result} (Time: {elapsed_time:.6f}s)"
        )

        return result, None  # âœ… No failure message if rule passed
    except Exception as e:
        logger.error(
            f"Rule evaluation failed due to unexpected error: {e}"
        )
        return False, str(e)


def batch_evaluate(rules, sequences):
    """
    Evaluates multiple rule functions against multiple sequences.

    :param rules: List of rule functions to evaluate
    :param sequences: List of sequences to evaluate
    :return: List of dictionaries containing evaluation results
    """
    if not sequences:
        return []

    if not isinstance(rules, (list, tuple)):
        rules = [rules]

    results = []
    for rule_func in rules:
        if not callable(rule_func):
            logger.error("Provided rule function is not callable.")
            continue

        for sequence in sequences:
            sequence_names = [obj.name for obj in sequence]
            logger.debug(
                f"Evaluating rule on sequence: {sequence_names}"
            )

            result, error = evaluate_rule(rule_func, sequence)
            results.append({
                "rule": "rule_function",  # Use generic name for consistency
                "sequence": sequence_names,
                "result": result,
                "failure_reason": error
            })

    return results


def profile_rule_execution(rule_func, test_sequences, runs=5):
    """
    Profiles execution time and memory usage of a rule over multiple runs.

    :param rule_func: Function generated by sequence_rule_generator
    :param test_sequences: List of sequences to evaluate
    :param runs: Number of times to repeat evaluation
    :return: Average execution time per sequence and average memory usage
    """
    logger.info(
        f"Profiling execution time and memory over {runs} runs"
    )

    total_time = 0
    total_memory = 0
    sequence_times = {}
    sequence_memory = {}

    for sequence in test_sequences:
        sequence_key = tuple(obj.name for obj in sequence)
        sequence_times[sequence_key] = []
        sequence_memory[sequence_key] = []

    for _ in range(runs):
        for sequence in test_sequences:
            sequence_key = tuple(obj.name for obj in sequence)

            tracemalloc.start()
            start_time = time.perf_counter()
            rule_func(sequence)
            elapsed_time = time.perf_counter() - start_time
            current, peak_memory = tracemalloc.get_traced_memory()
            tracemalloc.stop()

            total_time += elapsed_time
            total_memory += peak_memory / 1024  # Convert to KB
            sequence_times[sequence_key].append(elapsed_time)
            sequence_memory[sequence_key].append(peak_memory / 1024)

    avg_time = total_time / (runs * len(test_sequences))
    avg_memory = total_memory / (runs * len(test_sequences))

    avg_per_sequence_time = {seq: sum(times)/len(times) for seq, times in sequence_times.items()}
    avg_per_sequence_memory = {seq: sum(mem)/len(mem) for seq, mem in sequence_memory.items()}

    logger.info(f"Average execution time per sequence: {avg_per_sequence_time}")
    logger.info(f"Average memory usage per sequence (KB): {avg_per_sequence_memory}")
    logger.info(f"Overall average execution time: {avg_time:.6f}s")
    logger.info(f"Overall average memory usage (KB): {avg_memory:.2f} KB")

    return avg_time, avg_memory, avg_per_sequence_time, avg_per_sequence_memory
